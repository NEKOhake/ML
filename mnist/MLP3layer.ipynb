{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "81G6QCO3BSRa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81G6QCO3BSRa",
        "outputId": "0522337e-0c11-4500-af29-7a745376b1b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  train.zip\n",
            "replace train/train_0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  test.zip\n",
            "replace test/test_0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip train.zip\n",
        "!unzip test.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "47563854",
      "metadata": {
        "id": "47563854"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "PT4UKwyUrSI4",
      "metadata": {
        "id": "PT4UKwyUrSI4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "8ccc85c7",
      "metadata": {
        "id": "8ccc85c7"
      },
      "outputs": [],
      "source": [
        "def onehot(y,num_classes):\n",
        "    N = y.shape[0]\n",
        "    y_onehot = np.zeros((N,num_classes),dtype=\"float32\")\n",
        "    y_onehot[np.arange(N),y] = 1.0\n",
        "    return y_onehot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "a853c6bf",
      "metadata": {
        "id": "a853c6bf"
      },
      "outputs": [],
      "source": [
        "def softmax(x):\n",
        "    x_shift = x - np.max(x,axis=1,keepdims=True)\n",
        "    exp_x = np.exp(x_shift)\n",
        "    return exp_x / np.sum(exp_x,axis=1,keepdims=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "74d54285",
      "metadata": {
        "id": "74d54285"
      },
      "outputs": [],
      "source": [
        "def cross_entropy(pred,target_onehot):\n",
        "    eps = 1e-12\n",
        "    pred_clipped = np.clip(pred, eps, 1.0 - eps)\n",
        "    log_likehood = np.sum(target_onehot * np.log(pred_clipped), axis=1)\n",
        "    return -np.mean(log_likehood)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "8fa113f9",
      "metadata": {
        "id": "8fa113f9"
      },
      "outputs": [],
      "source": [
        "def accuracy(pred, y_true):\n",
        "    y_pred = np.argmax(pred, axis=1)\n",
        "    return np.mean(y_pred == y_true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b690fc34",
      "metadata": {
        "id": "b690fc34"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "c026503a",
      "metadata": {
        "id": "c026503a"
      },
      "outputs": [],
      "source": [
        "class MLP3layer:\n",
        "    def __init__(self, input_dim=784, hidden1=128, hidden2=64, output_dim=10, weight_scale=0.01, seed=42):\n",
        "        rng = np.random.default_rng(seed)\n",
        "        self.W1 = weight_scale * rng.standard_normal((input_dim, hidden1))\n",
        "        self.b1 = np.zeros(hidden1,dtype=\"float32\")\n",
        "\n",
        "        self.W2 = weight_scale * rng.standard_normal((hidden1,hidden2))\n",
        "        self.b2 = np.zeros(hidden2,dtype=\"float32\")\n",
        "\n",
        "        self.W3 = weight_scale * rng.standard_normal((hidden2,output_dim))\n",
        "        self.b3 = np.zeros(output_dim,dtype=\"float32\")\n",
        "\n",
        "\n",
        "    def forward(self,X):\n",
        "        z1 = X @ self.W1 + self.b1\n",
        "        a1 = np.maximum(0,z1)\n",
        "\n",
        "        z2 = a1 @ self.W2 + self.b2\n",
        "        a2 = np.maximum(0,z2)\n",
        "\n",
        "        z3 = a2 @ self.W3 + self.b3\n",
        "        y_pred = softmax(z3)\n",
        "\n",
        "        cache = (X, z1, a1, z2, a2, z3, y_pred)\n",
        "        return y_pred, cache\n",
        "\n",
        "    def backward(self,cache, y_true_onehot):\n",
        "        X, z1, a1, z2, a2, z3, y_pred = cache\n",
        "        N = X.shape[0]\n",
        "\n",
        "        dz3 = (y_pred - y_true_onehot) / N\n",
        "\n",
        "        dW3 = a2.T @ dz3\n",
        "        db3 = dz3.sum(axis=0)\n",
        "\n",
        "        da2 = dz3 @ self.W3.T\n",
        "        dz2 = da2 * (z2 > 0)\n",
        "\n",
        "        dW2 = a1.T @ dz2 # This was corrected from a2.T @ dz2 to a1.T @ dz2 previously\n",
        "        db2 = dz2.sum(axis=0)\n",
        "\n",
        "        da1 = dz2 @ self.W2.T\n",
        "        dz1 = da1 * (z1 > 0)\n",
        "\n",
        "        dW1 = X.T @ dz1 # This is the main correction\n",
        "        db1 = dz1.sum(axis = 0)\n",
        "\n",
        "        grads = {\n",
        "            \"W1\":dW1, \"b1\":db1,\n",
        "            \"W2\":dW2, \"b2\":db2,\n",
        "            \"W3\":dW3, \"b3\":db3,\n",
        "        }\n",
        "        return grads\n",
        "\n",
        "    def update(self, grads, lr=0.1, weight_decay=0.0):\n",
        "        if weight_decay > 0.0:\n",
        "            grads[\"W1\"] += weight_decay * self.W1\n",
        "            grads[\"W2\"] += weight_decay * self.W2\n",
        "            grads[\"W3\"] += weight_decay * self.W3\n",
        "\n",
        "        self.W1 -= lr * grads[\"W1\"]\n",
        "        self.b1 -= lr * grads[\"b1\"]\n",
        "        self.W2 -= lr * grads[\"W2\"]\n",
        "        self.b2 -= lr * grads[\"b2\"]\n",
        "        self.W3 -= lr * grads[\"W3\"]\n",
        "        self.b3 -= lr * grads[\"b3\"]\n",
        "\n",
        "    def predict_proba(self,x):\n",
        "        y_pred, _ = self.forward(x)\n",
        "        return y_pred\n",
        "\n",
        "    def predict(self, x):\n",
        "        y_pred, _ = self.forward(x)\n",
        "        return np.argmax(y_pred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "596ad42d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "596ad42d",
        "outputId": "be0d654d-1103-48cc-8ea3-233042a23301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "folder = \"./train/*.jpg\"\n",
        "paths = sorted(glob.glob(\"./train/*.jpg\"))\n",
        "imgs = []\n",
        "for path in paths:\n",
        "    img = Image.open(path)\n",
        "    imgs.append(img)\n",
        "X = np.array(imgs).astype(np.float32)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "bae4a35e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bae4a35e",
        "outputId": "62d5904e-91ac-4047-d336-5499f891c3f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float32(1.0)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = X.reshape(60000,-1)\n",
        "X /= 255\n",
        "np.max(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec85c7a1",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "xV-WcrPs5bYR",
      "metadata": {
        "id": "xV-WcrPs5bYR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "ae4b36ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae4b36ca",
        "outputId": "9fd0dc77-27a0-498f-f418-357f31e690bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000,)\n"
          ]
        }
      ],
      "source": [
        "y = pd.read_csv(\"./train_master.csv\")\n",
        "y = y.sort_values(\"file_name\")\n",
        "y = y[\"category_id\"].values\n",
        "y = y.reshape(-1)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NM9k239s_Mfq",
      "metadata": {
        "id": "NM9k239s_Mfq"
      },
      "outputs": [],
      "source": [
        "def train_mnist(\n",
        "    num_epochs = 10,\n",
        "    batch_size = 128,\n",
        "    lr = 0.1,\n",
        "    weight_decay = 1e-4\n",
        "):\n",
        "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "    num_classes = 10\n",
        "    model = MLP3layer(input_dim=784, hidden1=128, hidden2=64, output_dim=num_classes)\n",
        "    num_train = X_train.shape[0]\n",
        "    num_batches = num_train // batch_size\n",
        "\n",
        "    for epoch in range(1,num_epochs+1):\n",
        "\n",
        "        indices = np.random.permutation(num_train)\n",
        "        X_train_shuffled = X_train[indices]\n",
        "        y_train_shuffled = y_train[indices]\n",
        "\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for i in range(num_batches):\n",
        "            start = i * batch_size\n",
        "            end = start + batch_size\n",
        "            X_batch = X_train_shuffled[start:end]\n",
        "            y_batch = y_train_shuffled[start:end]\n",
        "\n",
        "            y_batch_onehot = onehot(y_batch, num_classes)\n",
        "\n",
        "            y_pred, cache = model.forward(X_batch)\n",
        "            loss = cross_entropy(y_pred, y_batch_onehot)\n",
        "            epoch_loss += loss\n",
        "\n",
        "            grads = model.backward(cache, y_batch_onehot)\n",
        "            model.update(grads, lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "        \n",
        "        train_pred, _ = model.forward(X_train[:5000])\n",
        "        train_acc = accuracy(train_pred, y_train[:5000])\n",
        "\n",
        "        test_pred, _ = model.forward(X_test)\n",
        "        test_acc = accuracy(test_pred, y_test)\n",
        "\n",
        "        print(f\"Epoch {epoch:2d} | loss={epoch_loss/num_batches:.4f} | \"\n",
        "              f\"train_acc={train_acc*100:.2f}% | test_acc={test_acc*100:.2f}%\")\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "zbY_d_sB5DhM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbY_d_sB5DhM",
        "outputId": "79eee8ba-d716-4f71-d3a3-445bedd38838"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  1 | loss=2.1786 | train_acc=57.40% | test_acc=57.33%\n",
            "Epoch  2 | loss=0.7483 | train_acc=83.24% | test_acc=82.56%\n",
            "Epoch  3 | loss=0.4296 | train_acc=90.60% | test_acc=90.48%\n",
            "Epoch  4 | loss=0.3090 | train_acc=92.28% | test_acc=91.75%\n",
            "Epoch  5 | loss=0.2409 | train_acc=94.36% | test_acc=93.87%\n",
            "Epoch  6 | loss=0.1958 | train_acc=95.02% | test_acc=94.67%\n",
            "Epoch  7 | loss=0.1648 | train_acc=95.34% | test_acc=94.92%\n",
            "Epoch  8 | loss=0.1429 | train_acc=96.50% | test_acc=95.77%\n",
            "Epoch  9 | loss=0.1253 | train_acc=96.38% | test_acc=95.75%\n",
            "Epoch 10 | loss=0.1102 | train_acc=96.92% | test_acc=96.12%\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    model = train_mnist(\n",
        "        num_epochs=10,\n",
        "        batch_size=128,\n",
        "        lr=0.1,\n",
        "        weight_decay=1e-4\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
