{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a1a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0714ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1e295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encode_oof(\n",
    "        train:pd.DataFrame,\n",
    "        test:pd.DataFrame,\n",
    "        cat_cols,\n",
    "        y_col: str,\n",
    "        n_splits: int = 5,\n",
    "        random_state: int = 42,\n",
    "        smooth: float | None = None,\n",
    "        prefix: str = \"_te\",\n",
    "):\n",
    "    \n",
    "    if isinstance(cat_cols,(str,bytes)):\n",
    "        cat_cols = [cat_cols]\n",
    "    \n",
    "    train_out = train.copy()\n",
    "    test_out = test.copy()\n",
    "    y = train_out[y_col].values\n",
    "    global_mean = y.mean()\n",
    "    \n",
    "\n",
    "    kf = KFold(n_splits=n_splits,shuffle = True, random_state = random_state)\n",
    "    splits = list(kf.split(train_out))\n",
    "\n",
    "    for col in cat_cols:\n",
    "        oof_encoded = np.zeros(len(train_out))\n",
    "\n",
    "        for tr_idx, val_idx in splits:\n",
    "            tr = train_out.iloc[tr_idx]\n",
    "            val = train_out.iloc[val_idx]\n",
    "            stats = tr.groupby(col)[y_col].agg([\"mean\",\"count\"])\n",
    "            if smooth is not None:\n",
    "                n = stats[\"count\"]\n",
    "                m = stats[\"mean\"]\n",
    "                stats[\"te\"] = (n * m + smooth * global_mean) / (n + smooth)\n",
    "            else:\n",
    "                stats[\"te\"] = stats[\"mean\"]\n",
    "            \n",
    "            mapping = stats[\"te\"]\n",
    "            val_encoded = val[col].map(mapping)\n",
    "            oof_encoded[val_idx] = val_encoded.values\n",
    "        new_col = f\"{col}{prefix}\"\n",
    "        train_out[new_col] = oof_encoded\n",
    "   \n",
    "\n",
    "        stats_full = train_out.groupby(col)[y_col].agg([\"mean\",\"count\"])\n",
    "        if smooth is not None:\n",
    "            n = stats_full[\"count\"]\n",
    "            m = stats_full[\"mean\"]\n",
    "            stats_full[\"te\"] = (n * m + smooth * global_mean) / (n + smooth)\n",
    "        else:\n",
    "            stats_full[\"te\"] = stats_full[\"mean\"]\n",
    "        mapping_full = stats_full[\"te\"]\n",
    "        test_out[new_col] = test_out[col].map(mapping_full).fillna(global_mean)\n",
    "    return train_out,test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a59adb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./train.csv\")\n",
    "df_test = pd.read_csv(\"./test.csv\")\n",
    "cat_cols = df_train.select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
    "num_cols = df_train.select_dtypes(include=[\"float64\",\"int64\"]).drop(columns=\"y\").columns.tolist()\n",
    "y_col = \"y\"\n",
    "train_te,test_te = target_encode_oof(\n",
    "    train=df_train,\n",
    "    test=df_test,\n",
    "    cat_cols=cat_cols,\n",
    "    y_col=y_col,\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "    smooth=20,   \n",
    "    prefix=\"_te\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddf0107",
   "metadata": {},
   "outputs": [],
   "source": [
    "te_cols = [c + \"_te\" for c in cat_cols]\n",
    "feature_cols = te_cols + num_cols\n",
    "X = train_te[feature_cols]\n",
    "y = train_te[\"y\"]\n",
    "X_test = test_te[feature_cols]\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:,1]\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89163bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89e3512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(\n",
    "    {\n",
    "        \"index\":range(len(y_pred_proba)),\n",
    "        \"proba\":y_pred_proba,\n",
    "    }\n",
    ")\n",
    "output.to_csv(\"out.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
